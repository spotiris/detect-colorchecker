{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T03:52:01.736193Z",
     "start_time": "2019-02-01T03:51:59.449648Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from glob import glob\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0\n",
    "import keras\n",
    "import keras.layers as layers\n",
    "import matplotlib.colors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tqdm\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from keras_applications.mobilenet_v2 import MobileNetV2  # , preprocess_input\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.transform import resize\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T03:52:01.741328Z",
     "start_time": "2019-02-01T03:52:01.737816Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_mask_name(filename):\n",
    "    groups = re.match(\"(\\d)+_IMG_(\\d+).tiff\", filename).groups()\n",
    "    return \"mask1_IMG_{:s}.tiff\".format(groups[1])\n",
    "\n",
    "def resize(image, output_shape):\n",
    "    \"\"\"Fast resize using PIL (ensure pillow-simd is installed instead of pillow)\"\"\"\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    image = image.resize(output_shape[:2])\n",
    "    return np.array(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T03:52:15.809301Z",
     "start_time": "2019-02-01T03:52:01.742989Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IMAGE_DIR = \"/data/standard/ColorCheckerRECommended/5D - part 1\"\n",
    "MASK_DIR = \"/data/standard/ColorCheckerRECommended/5D - part 1/masks\"\n",
    "INPUT_SHAPE = (224, 224, 3)\n",
    "RESIZE_SHAPE = INPUT_SHAPE[:2]\n",
    "\n",
    "images, masks, categories = [], [], []\n",
    "image_paths = glob(IMAGE_DIR +  \"/*.tiff\")\n",
    "print(\"Loading {:d} positive images\".format(len(image_paths)))\n",
    "for image_path in tqdm.tqdm_notebook(image_paths):\n",
    "    filename = os.path.basename(image_path)\n",
    "    mask_name = get_mask_name(filename)\n",
    "    images.append(resize(imread(os.path.join(IMAGE_DIR, filename)), output_shape=RESIZE_SHAPE))\n",
    "    masks.append(resize(imread(os.path.join(MASK_DIR, mask_name))[..., 0], output_shape=RESIZE_SHAPE) < 0.5)\n",
    "categories += [1] * len(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T03:52:42.149309Z",
     "start_time": "2019-02-01T03:52:15.810889Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load application specific negatives\n",
    "image_paths = glob(\"/data/acfr/ladybird/sym/all/images/cc_det_train/*.jpg\")\n",
    "for image_path in tqdm.tqdm_notebook(image_paths):\n",
    "    filename = os.path.basename(image_path)\n",
    "    image = resize(imread(image_path), output_shape=RESIZE_SHAPE)\n",
    "    images.append(image)\n",
    "    masks.append(np.zeros(image.shape[:2], dtype=np.uint8))\n",
    "categories += [0] * len(image_paths)\n",
    "\n",
    "# Load application specific positives\n",
    "image_paths = glob(\"/data/acfr/ladybird/sym/all/images/cc_det_train/positive/*.jpg\")\n",
    "for image_path in tqdm.tqdm_notebook(image_paths):\n",
    "    filename = os.path.basename(image_path)\n",
    "    image = resize(imread(image_path), output_shape=RESIZE_SHAPE)\n",
    "    images.append(image)\n",
    "    masks.append(np.zeros(image.shape[:2], dtype=np.uint8))\n",
    "categories += [1] * len(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T03:52:42.226431Z",
     "start_time": "2019-02-01T03:52:42.151053Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(images), len(masks), len(categories))\n",
    "print(\"images\", images[0].shape, images[-1].shape)\n",
    "print(\"masks\", masks[0].shape, masks[-1].shape)\n",
    "assert images[0].shape == images[-1].shape\n",
    "assert masks[0].shape == masks[-1].shape\n",
    "assert len(images) == len(masks) == len(categories)\n",
    "images = np.array(images, dtype=np.uint8)\n",
    "masks = np.array(masks, dtype=np.uint8)[..., np.newaxis]\n",
    "categories = np.array(categories, dtype=np.uint8)\n",
    "categories = to_categorical(categories, num_classes=2)\n",
    "print(images.shape, masks.shape, categories.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T03:52:44.751721Z",
     "start_time": "2019-02-01T03:52:42.228112Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(images[:482].reshape([-1, 3]), log=True)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(images[482:].reshape([-1, 3]), log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T03:52:44.757008Z",
     "start_time": "2019-02-01T03:52:44.753502Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load application specific negatives\n",
    "def get_random_blind():\n",
    "    test_blind_dir = glob(\"/data/acfr/ladybird/sym/all/images/rgb_small_jpg/left/*.jpg\")\n",
    "    image_path = np.random.choice(test_blind_dir)\n",
    "    filename = os.path.basename(image_path)\n",
    "    return resize(imread(image_path), output_shape=RESIZE_SHAPE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T03:52:44.797679Z",
     "start_time": "2019-02-01T03:52:44.758437Z"
    }
   },
   "outputs": [],
   "source": [
    "from imgaug import augmenters as iaa\n",
    "from itertools import zip_longest\n",
    "\n",
    "def grouper(iterable, n, fillvalue=None):\n",
    "    args = [iter(iterable)] * n\n",
    "    return zip_longest(*args, fillvalue=fillvalue)\n",
    "\n",
    "seq_geom = iaa.Sequential([\n",
    "    iaa.Fliplr(0.5), # horizontally flip 50% of the images\n",
    "    iaa.Flipud(0.5), # horizontally flip 50% of the images\n",
    "    iaa.Affine(\n",
    "        scale={\"x\": (0.9, 1.2), \"y\": (0.9, 1.2)},\n",
    "        translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
    "        rotate=(-25, 25),\n",
    "        shear=(-8, 8)\n",
    "    ),\n",
    "])\n",
    "seq_col = iaa.Sequential([\n",
    "    iaa.ContrastNormalization((0.9, 1.1)),\n",
    "    iaa.Multiply((0.9, 1.1), per_channel=0.2),\n",
    "    iaa.Add((-10, 10), per_channel=0.5),\n",
    "#     iaa.Grayscale(alpha=(0.5, 1.0)),\n",
    "])\n",
    "\n",
    "def aug_gen(x, y, batch_size, fillvalue=None, augment=False):\n",
    "    while True:\n",
    "        for images, masks in zip(grouper(x, batch_size, fillvalue), grouper(y, batch_size, fillvalue)):\n",
    "            xx = np.array([xxx for xxx in images if xxx is not None])\n",
    "            yy = np.array([yyy for yyy in masks if yyy is not None])\n",
    "            \n",
    "            if augment:\n",
    "                seq_det = seq_geom.to_deterministic()\n",
    "                xx = seq_det.augment_images(xx)\n",
    "                xx = seq_col.augment_images(xx)\n",
    "            yield xx, yy\n",
    "            \n",
    "def cce_from_sigmoid_seg_gen(gen):\n",
    "    for images, masks in gen:\n",
    "        masks_cce = np.concatenate([masks <= 0, masks > 0], axis=-1)\n",
    "        yield images, masks_cce\n",
    "        \n",
    "def classification_from_seg(gen, output='sigmoid'):\n",
    "    for images, masks in gen:\n",
    "        if output == 'sigmoid':\n",
    "            classes = np.array([\n",
    "                1 if np.count_nonzero(batch) else 0\n",
    "                for batch in masks])\n",
    "        elif output == 'softmax':\n",
    "            classes = np.array(\n",
    "                [[0, 1] if np.count_nonzero(batch) else [1, 0]\n",
    "                for batch in masks])\n",
    "        yield images, classes\n",
    "        \n",
    "# def preprocess_gen(gen):\n",
    "#     for images, masks in gen:\n",
    "#         yield preprocess_input(images.astype(np.float32)), masks\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T02:44:51.636302Z",
     "start_time": "2019-02-01T02:44:51.567650Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T03:52:44.938627Z",
     "start_time": "2019-02-01T03:52:44.799444Z"
    }
   },
   "outputs": [],
   "source": [
    "(X_train, X_test, y_train, y_test) = train_test_split(images, categories, shuffle=True, test_size=0.2)\n",
    "[i.setflags(write=False) for i in [X_train, X_test, y_train, y_test]]\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape\n",
    "print(\"train\", np.count_nonzero(y_train.argmax(-1) == 1) / y_train.shape[0])\n",
    "print(\"test\", np.count_nonzero(y_test.argmax(-1) == 1) / y_test.shape[0])\n",
    "\n",
    "found = [0, 0]\n",
    "plt.figure()\n",
    "for xx, yy in aug_gen(X_train, y_train, batch_size=1, augment=True):\n",
    "    class_id = int(yy.argmax(-1).ravel())\n",
    "    if not found[class_id]:\n",
    "        print(xx.shape, yy.shape, xx.dtype, yy.dtype)\n",
    "        print(xx.min(), xx.max(), yy.min(), yy.max())\n",
    "        print(xx[0].min(), xx[0].mean(), xx[0].max(), xx[0].std())\n",
    "        image = np.clip(100*np.log10(1+xx[0]), 0, 255).astype(np.uint8)\n",
    "        plt.subplot(1, 2, 1 + class_id)\n",
    "        plt.imshow(image)\n",
    "        plt.title(str(class_id))\n",
    "        found[class_id] += 1\n",
    "    if all(found):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T03:52:44.943575Z",
     "start_time": "2019-02-01T03:52:44.940585Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T04:10:06.334461Z",
     "start_time": "2019-02-01T04:10:06.323066Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_preprocess(model):\n",
    "    seq = Sequential([\n",
    "        layers.InputLayer(input_shape=INPUT_SHAPE, dtype='float32'),\n",
    "        layers.Lambda(lambda x: x / 127.5 - 1, output_shape=INPUT_SHAPE),\n",
    "        model\n",
    "    ])\n",
    "    return seq\n",
    "\n",
    "def make_model(weights, heads_only=False):\n",
    "    x_in = layers.Input(shape=INPUT_SHAPE, dtype='float32')\n",
    "    x = x_in\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(32, (3, 3), strides=(2, 2), activation='relu', dilation_rate=1)(x)\n",
    "    x = layers.Conv2D(64, (3, 3), strides=(1, 1), activation='relu', dilation_rate=6)(x)\n",
    "    x = layers.Conv2D(128, (3, 3), strides=(1, 1), activation='relu', dilation_rate=24)(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    y = layers.Dense(2, activation='softmax')(x)\n",
    "    model = Model(x_in, y)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T04:10:57.131815Z",
     "start_time": "2019-02-01T04:10:57.125831Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_model(weights, heads_only=True):\n",
    "    global model\n",
    "    del model\n",
    "    keras.backend.clear_session()\n",
    "    model = MobileNetV2(input_shape=INPUT_SHAPE, include_top=False, weights=weights)\n",
    "    x = model.output\n",
    "#     x = model.get_layer(\"block_12_add\").output\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    y = layers.Dense(2, activation='softmax')(x)\n",
    "    model = Model(model.input, y)\n",
    "    if heads_only:\n",
    "        for layer in model.layers[:-3]:\n",
    "            layer.trainable = False\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T04:10:57.337508Z",
     "start_time": "2019-02-01T04:10:57.331794Z"
    }
   },
   "outputs": [],
   "source": [
    "# def make_model(weights, heads_only=True):\n",
    "#     global model\n",
    "#     del model\n",
    "#     keras.backend.clear_session()\n",
    "#     model = MobileNetV2(input_shape=INPUT_SHAPE, include_top=False, weights=weights)\n",
    "#     x = model.output\n",
    "# #     x = model.get_layer(\"block_12_add\").output\n",
    "#     x = layers.GlobalAveragePooling2D()(x)\n",
    "#     x = layers.Dense(2)(x)\n",
    "#     y = layers.Activation('sigmoid')(x)\n",
    "#     model = Model(model.input, y)\n",
    "#     if heads_only:\n",
    "#         trainable_layers = model.layers[-3:] + [layer for layer in model.layers[:-3] if False]\n",
    "#         untrainable_layers = [layer for layer in model.layers if layer not in trainable_layers]\n",
    "#         for layer in untrainable_layers:\n",
    "#             layer.trainable = False\n",
    "#         print(\"Trainable layers:\")\n",
    "#         print([layer.name for layer in trainable_layers])\n",
    "#         print(\"Untrainable layers:\")\n",
    "#         print([layer.name for layer in untrainable_layers])\n",
    "#     model.compile('nadam', 'binary_crossentropy',\n",
    "#                   metrics=['acc', auc_factory('PR')])\n",
    "#     return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T04:11:08.358352Z",
     "start_time": "2019-02-01T04:10:57.757405Z"
    }
   },
   "outputs": [],
   "source": [
    "model = None\n",
    "\n",
    "model = make_model(weights='imagenet', heads_only=False)\n",
    "model = model_preprocess(model)\n",
    "model.compile('nadam', 'categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T04:12:37.266896Z",
     "start_time": "2019-02-01T04:11:08.360085Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(lr, epochs, batch_size=10, augment=True):\n",
    "    gen_train = aug_gen(X_train, y_train, batch_size=batch_size, augment=augment)\n",
    "#     gen_val = aug_gen(X_test, y_test, batch_size=batch_size)\n",
    "    keras.backend.set_value(model.optimizer.lr, lr)\n",
    "    model.fit_generator(\n",
    "        gen_train, steps_per_epoch=len(X_train)//batch_size,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=epochs, class_weight={0: 1, 1: 2})\n",
    "train(1e-6, 1)\n",
    "train(1e-4, 9)\n",
    "# train(1e-5, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T03:50:27.165774Z",
     "start_time": "2019-02-01T03:50:26.953971Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T04:12:38.546219Z",
     "start_time": "2019-02-01T04:12:37.271066Z"
    }
   },
   "outputs": [],
   "source": [
    "pred = model.predict((X_test.astype(np.float32)))\n",
    "np.count_nonzero(pred.argmax(-1) == y_test.argmax(-1)) / y_test.shape[0]\n",
    "print(confusion_matrix(y_test.argmax(-1), pred.argmax(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T03:13:00.750330Z",
     "start_time": "2019-02-01T03:13:00.745077Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T03:54:41.169395Z",
     "start_time": "2019-02-01T03:54:37.634802Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test on val data\n",
    "plt.figure(figsize=(6,6))\n",
    "found = {i: 0 for i in \"TP,FP,FN,TN\".split(\",\")}\n",
    "i = 0\n",
    "while not all(found.values()):\n",
    "    i += 1\n",
    "    idx = np.random.choice(range(X_test.shape[0]))\n",
    "    try:\n",
    "        pred = model.predict(X_test[idx:idx+1].astype(np.float32))[0]\n",
    "    except NameError:\n",
    "        pred = None\n",
    "    image, mask = X_test[idx], y_test[idx]\n",
    "    image = np.clip(100*np.log10(1+image), 0, 255).astype(np.uint8)\n",
    "    \n",
    "    if pred is not None:\n",
    "        pred_class = pred.argmax(-1)\n",
    "        gt_class = mask.argmax(-1)\n",
    "        TP = pred_class and pred_class == gt_class\n",
    "        FP = pred_class and pred_class != gt_class\n",
    "        TN = not pred_class and pred_class == gt_class\n",
    "        FN = not pred_class and pred_class != gt_class\n",
    "        if not found['TP'] and TP:\n",
    "            plt.subplot(2, 2, 1)\n",
    "            plt.imshow(image)\n",
    "            plt.title(\"TP\")\n",
    "            found['TP'] = 1\n",
    "        if not found['TN'] and TN:\n",
    "            plt.subplot(2, 2, 4)\n",
    "            plt.imshow(image)\n",
    "            plt.title(\"TN\")\n",
    "            found['TN'] = 1\n",
    "        if not found['FP'] and FP:\n",
    "            plt.subplot(2, 2, 2)\n",
    "            plt.imshow(image)\n",
    "            plt.title(\"FP\")\n",
    "            found['FP'] = 1\n",
    "        if not found['FN'] and FN:\n",
    "            plt.subplot(2, 2, 3)\n",
    "            plt.imshow(image)\n",
    "            plt.title(\"FN\")\n",
    "            found['FN'] = 1\n",
    "    if i == len(y_test):\n",
    "        break\n",
    "        \n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T04:24:36.538887Z",
     "start_time": "2019-02-01T04:24:34.693737Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test on test_blind\n",
    "pred = None\n",
    "while pred != 1:\n",
    "    image = get_random_blind()\n",
    "    image_show = np.clip(10*np.log10(1+image), 0, 1)\n",
    "    pred = int(model.predict(image[np.newaxis]).argmax(-1)[0])\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow(image*3)\n",
    "plt.title(str(pred));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T04:12:45.882019Z",
     "start_time": "2019-02-01T04:12:45.871813Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_model(model, dest_dir):\n",
    "    model.save_weights(os.path.join(dest_dir, \"weights.h5\"))\n",
    "    with open(os.path.join(dest_dir, \"model.json\"), \"w\") as file:\n",
    "        file.write(model.to_json())\n",
    "    \n",
    "def load_model(src_dir):\n",
    "    from keras.models import model_from_json\n",
    "    with open(os.path.join(src_dir, \"model.json\"), \"r\") as file:\n",
    "        model_json = file.read()\n",
    "    model = model_from_json(model_json)\n",
    "    model.load_weights(os.path.join(src_dir, \"weights.h5\"))\n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T04:12:46.720480Z",
     "start_time": "2019-02-01T04:12:46.348469Z"
    }
   },
   "outputs": [],
   "source": [
    "save_model(model, dest_dir=\"/data/standard/ColorCheckerRECommended/model\")\n",
    "# model = load_model(src_dir=\"/data/standard/ColorCheckerRECommended/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-31T01:40:28.015664Z",
     "start_time": "2019-01-31T01:40:28.008176Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T03:54:28.530032Z",
     "start_time": "2019-02-01T03:51:59.463Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
